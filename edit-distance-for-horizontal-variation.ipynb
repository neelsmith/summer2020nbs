{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Constructing a matrix of edit distances as a measure of horizontal variation\n",
        "\n",
        "\n",
        "This notebook first builds a corpus of aligned texts. (See fuller explanation in related NB.)\n",
        "\n",
        "It then computes a matrix of edit-distance scores for each line of each MS against the corresponding line of every MS.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 1. Building aligned corpora"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// Configure notebook\n",
        "val personalRepo = coursierapi.MavenRepository.of(\"https://dl.bintray.com/neelsmith/maven\")\n",
        "interp.repositories() ++= Seq(personalRepo)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import $ivy.`edu.holycross.shot.cite::xcite:4.3.0`\n",
        "import $ivy.`edu.holycross.shot::ohco2:10.20.3`\n",
        "import $ivy.`edu.holycross.shot::greek:5.5.1`\n",
        "import $ivy.`edu.holycross.shot.mid::orthography:2.0.0`"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import edu.holycross.shot.cite._\n",
        "import edu.holycross.shot.ohco2._\n",
        "import edu.holycross.shot.greek._\n",
        "import edu.holycross.shot.mid.orthography._\n",
        "\n",
        "\n",
        "val venetusAUrl = \"https://raw.githubusercontent.com/neelsmith/summer2020nbs/master/data/vaIliad-2020i.cex\"\n",
        "val twins9Url = \"https://raw.githubusercontent.com/neelsmith/summer2020nbs/master/data/twins9corpus.cex\"\n",
        "val allenUrl = \"https://raw.githubusercontent.com/neelsmith/summer2020nbs/master/data/iliad-allen.cex\"\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// create  source corpora\n",
        "val twins9 = CorpusSource.fromUrl(twins9Url)\n",
        "val allen = CorpusSource.fromUrl(allenUrl)\n",
        "val venetusA = CorpusSource.fromUrl(venetusAUrl)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// Iliad, here book 10 only\n",
        "val venetusAIliad9 = venetusA  ~~ CtsUrn(\"urn:cts:greekLit:tlg0012.tlg001.msA:9\")\n",
        "val venetusBIliad9 = twins9 ~~ CtsUrn(\"urn:cts:greekLit:tlg0012.tlg001.msB:9\")\n",
        "val oopsIliad9 = twins9 ~~ CtsUrn(\"urn:cts:greekLit:tlg0012.tlg001.e3:9\")\n",
        "val allenIliad9 = allen ~~ CtsUrn(\"urn:cts:greekLit:tlg0012.tlg001.allen:9\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "/*\n",
        "- tokenize, keep only lexical tokens\n",
        "- make LiteraryGreekStrings from lexical tokens, drop accents and breathings\n",
        "- recompose into a single stripped-down string for each line\n",
        "*/\n",
        "def curateNode(cn: CitableNode, siglum: String) : CitableNode = {\n",
        "  if (cn.text.isEmpty){\n",
        "    println(\"EMPTY TEXT: \" + cn.urn)\n",
        "    cn\n",
        "  } else {\n",
        "\n",
        "    val lexTokens = LiteraryGreekString.tokenizeNode(cn).filter(_.tokenCategory == Some(LexicalToken))\n",
        "    val lgs = lexTokens.map(tkn => LiteraryGreekString(tkn.text).toLower.stripBreathingAccent.ascii)\n",
        "    val simpleAscii = lgs.mkString(\" \")\n",
        "    CitableNode(cn.urn.addVersion(s\"${siglum}_simpleascii\"),simpleAscii)\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "def asciiCorpus(c: Corpus, siglum: String) : Corpus = {\n",
        "  Corpus(c.nodes.map(n => curateNode(n, siglum)))\n",
        "}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// These are agonizingly slow\n",
        "val oopsIliad9ascii = asciiCorpus(oopsIliad9, \"e3\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val venetusBIliad9ascii = asciiCorpus(oopsIliad9, \"msB\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "println(oopsIliad9ascii.size + \" vs \" + venetusBIliad9ascii.size)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val venetusAIliad9ascii = asciiCorpus(venetusAIliad9, \"msA\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val allenIliad9ascii = asciiCorpus(allenIliad9, \"allen\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// align corpora.\n",
        "def extractMatches(c: Corpus, ulist: Vector[CtsUrn]) = {\n",
        "  val nodes = for (urn <- ulist) yield {\n",
        "    val matchCorpus = c ~~ urn\n",
        "    //println(\"MATCHED \" + matchCorpus.size)\n",
        "    matchCorpus.size match {\n",
        "      case 0 => Vector(CitableNode(urn, \"\"))\n",
        "      case _ => matchCorpus.nodes\n",
        "    }\n",
        "  }\n",
        "  Corpus(nodes.flatten)\n",
        "}\n",
        "\n",
        "\n",
        "val urnList = oopsIliad9ascii.nodes.map(_.urn.dropVersion)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the final results we want:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val alignedTexts = Vector(\n",
        "  oopsIliad9ascii,\n",
        "  extractMatches(venetusBIliad9ascii, urnList),\n",
        "  extractMatches(venetusAIliad9ascii, urnList),\n",
        "  extractMatches(allenIliad9ascii, urnList)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Compute the matrix"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "//////////////////////////////////////////////////////////////\n",
        "// Edit distance using Levenshtein method\n",
        "import scala.collection.mutable\n",
        "import scala.collection.parallel.ParSeq\n",
        "\n",
        "// Implementation from RosettaCode:\n",
        "// https://rosettacode.org/wiki/Levenshtein_distance\n",
        "def levenshteinMemo(s1: String, s2: String): mutable.Map[(Int, Int), Int] = {\n",
        "  val memoizedCosts = mutable.Map[(Int, Int), Int]()\n",
        "\n",
        "  def lev: ((Int, Int)) => Int = {\n",
        "    case (k1, k2) =>\n",
        "      memoizedCosts.getOrElseUpdate((k1, k2), (k1, k2) match {\n",
        "        case (i, 0) => i\n",
        "        case (0, j) => j\n",
        "        case (i, j) =>\n",
        "          ParSeq(1 + lev((i - 1, j)),\n",
        "                 1 + lev((i, j - 1)),\n",
        "                 lev((i - 1, j - 1))\n",
        "                   + (if (s1(i - 1) != s2(j - 1)) 1 else 0)).min\n",
        "      })\n",
        "  }\n",
        "  lev((s1.length, s2.length))\n",
        "  memoizedCosts\n",
        "}\n",
        "\n",
        "def editDistance(s1: String, s2: String) : Int = {\n",
        "  levenshteinMemo(s1, s2)((s1.length, s2.length))\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def rowData(baseLine: String, cfTexts: Vector[String]) : Vector[Int] = {\n",
        "  val data = for (i <- 0 until cfTexts.size) yield {\n",
        "    editDistance(baseLine, cfTexts(i))\n",
        "  }\n",
        "  data.toVector\n",
        "}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// get text content of parallel URNs\n",
        "def parallelTexts(urn: CtsUrn, corpora: Vector[Corpus]): Vector[String] = {\n",
        "  corpora.map(c => {\n",
        "    val matches = c ~~ urn\n",
        "    matches.nodes.head.text })\n",
        "}\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val sigla = alignedTexts.map(c => c.nodes(3).urn.version)\n",
        "val colLabels = \"base,\" + sigla.mkString(\",\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def dataMatrix = for (documentsIndex <- 0 until alignedTexts.size) yield {\n",
        "  println(\"Document \" + documentsIndex + s\" (of ${alignedTexts.size})\")\n",
        "  \n",
        "  val baseText = alignedTexts(documentsIndex)\n",
        "  val colName = baseText.nodes.head.urn.version\n",
        "  println(colName)\n",
        "  val datacorpus = for (lineIndex <- 0 until baseText.size) yield {\n",
        "    val baseTextPassage = baseText.nodes(lineIndex)\n",
        "    val rowLabel = s\"${sigla(documentsIndex)}:\" + baseTextPassage.urn.passageComponent\n",
        "    println(rowLabel)\n",
        "    val cfLines = parallelTexts(baseTextPassage.urn.dropVersion, alignedTexts)\n",
        "\n",
        "    println(\"Computing edit distance against \" + rowLabel + s\" (psg ${lineIndex} in document ${documentsIndex})\")\n",
        "    val data = rowData(baseTextPassage.text, cfLines)\n",
        "    rowLabel + \",\" + data.mkString(\",\") \n",
        "  }\n",
        "  println(\"Done.\")\n",
        "  datacorpus\n",
        "}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val dm = dataMatrix"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's the final .csv output:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "println(colLabels + \"\\n\" + dm.flatten.mkString(\"\\n\"))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Scala (2.12)",
      "language": "scala",
      "name": "scala212"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "nbconvert_exporter": "script",
      "version": "2.12.10"
    },
    "nteract": {
      "version": "0.24.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}