{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a matrix of edit distances as a measure of horizontal variation\n",
    "\n",
    "\n",
    "This notebook first builds a corpus of aligned texts. (See fuller explanation in related NB.)\n",
    "\n",
    "It then computes a matrix of edit-distance scores for each line of each MS against the corresponding line of every MS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1. Building aligned corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Configure notebook\n",
    "val personalRepo = coursierapi.MavenRepository.of(\"https://dl.bintray.com/neelsmith/maven\")\n",
    "interp.repositories() ++= Seq(personalRepo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`edu.holycross.shot.cite::xcite:4.3.0`\n",
    "import $ivy.`edu.holycross.shot::ohco2:10.20.3`\n",
    "import $ivy.`edu.holycross.shot::greek:5.5.1`\n",
    "import $ivy.`edu.holycross.shot.mid::orthography:2.0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edu.holycross.shot.cite._\n",
    "import edu.holycross.shot.ohco2._\n",
    "import edu.holycross.shot.greek._\n",
    "import edu.holycross.shot.mid.orthography._\n",
    "\n",
    "\n",
    "val venetusAUrl = \"https://raw.githubusercontent.com/neelsmith/summer2020nbs/master/data/vaIliad-2020i.cex\"\n",
    "val twins10Url = \"https://raw.githubusercontent.com/neelsmith/summer2020nbs/master/data/twins10corpus.cex\"\n",
    "val allenUrl = \"https://raw.githubusercontent.com/neelsmith/summer2020nbs/master/data/iliad-allen.cex\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// create  source corpora\n",
    "val twins10 = CorpusSource.fromUrl(twins10Url)\n",
    "val allen = CorpusSource.fromUrl(allenUrl)\n",
    "val venetusA = CorpusSource.fromUrl(venetusAUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Iliad, here book 10 only\n",
    "val venetusAIliad10 = venetusA  ~~ CtsUrn(\"urn:cts:greekLit:tlg0012.tlg001.msA:10\")\n",
    "val oopsIliad = twins10 ~~ CtsUrn(\"urn:cts:greekLit:tlg0012.tlg001.e3:\")\n",
    "val allenIliad10 = allen ~~ CtsUrn(\"urn:cts:greekLit:tlg0012.tlg001.allen:10\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    "- tokenize, keep only lexical tokens\n",
    "- make LiteraryGreekStrings from lexical tokens, drop accents and breathings\n",
    "- recompose into a single stripped-down string for each line\n",
    "*/\n",
    "def curateNode(cn: CitableNode, siglum: String) : CitableNode = {\n",
    "  if (cn.text.isEmpty){\n",
    "    println(\"EMPTY TEXT: \" + cn.urn)\n",
    "    cn\n",
    "  } else {\n",
    "\n",
    "    val lexTokens = LiteraryGreekString.tokenizeNode(cn).filter(_.tokenCategory == Some(LexicalToken))\n",
    "    val lgs = lexTokens.map(tkn => LiteraryGreekString(tkn.text).toLower.stripBreathingAccent.ascii)\n",
    "    val simpleAscii = lgs.mkString(\" \")\n",
    "    CitableNode(cn.urn.addVersion(s\"${siglum}_simpleascii\"),simpleAscii)\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "def asciiCorpus(c: Corpus, siglum: String) : Corpus = {\n",
    "  Corpus(c.nodes.map(n => curateNode(n, siglum)))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// These are agonizingly slow\n",
    "val oopsIliad10ascii = asciiCorpus(oopsIliad, \"e3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val venetusAIliad10ascii = asciiCorpus(venetusAIliad10, \"msA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val allenIliad10ascii = asciiCorpus(allenIliad10, \"allen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// align corpora.\n",
    "def extractMatches(c: Corpus, ulist: Vector[CtsUrn]) = {\n",
    "  val nodes = for (urn <- ulist) yield {\n",
    "    val matchCorpus = c ~~ urn\n",
    "    //println(\"MATCHED \" + matchCorpus.size)\n",
    "    matchCorpus.size match {\n",
    "      case 0 => Vector(CitableNode(urn, \"\"))\n",
    "      case _ => matchCorpus.nodes\n",
    "    }\n",
    "  }\n",
    "  Corpus(nodes.flatten)\n",
    "}\n",
    "\n",
    "\n",
    "val urnList = oopsIliad10ascii.nodes.map(_.urn.dropVersion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the final results we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val alignedTexts = Vector(\n",
    "  oopsIliad10ascii,\n",
    "  extractMatches(venetusAIliad10ascii, urnList),\n",
    "  extractMatches(allenIliad10ascii, urnList)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//////////////////////////////////////////////////////////////\n",
    "// Edit distance using Levenshtein method\n",
    "import scala.collection.mutable\n",
    "import scala.collection.parallel.ParSeq\n",
    "\n",
    "// Implementation from RosettaCode:\n",
    "// https://rosettacode.org/wiki/Levenshtein_distance\n",
    "def levenshteinMemo(s1: String, s2: String): mutable.Map[(Int, Int), Int] = {\n",
    "  val memoizedCosts = mutable.Map[(Int, Int), Int]()\n",
    "\n",
    "  def lev: ((Int, Int)) => Int = {\n",
    "    case (k1, k2) =>\n",
    "      memoizedCosts.getOrElseUpdate((k1, k2), (k1, k2) match {\n",
    "        case (i, 0) => i\n",
    "        case (0, j) => j\n",
    "        case (i, j) =>\n",
    "          ParSeq(1 + lev((i - 1, j)),\n",
    "                 1 + lev((i, j - 1)),\n",
    "                 lev((i - 1, j - 1))\n",
    "                   + (if (s1(i - 1) != s2(j - 1)) 1 else 0)).min\n",
    "      })\n",
    "  }\n",
    "  lev((s1.length, s2.length))\n",
    "  memoizedCosts\n",
    "}\n",
    "\n",
    "def editDistance(s1: String, s2: String) : Int = {\n",
    "  levenshteinMemo(s1, s2)((s1.length, s2.length))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowData(baseLine: String, cfTexts: Vector[String]) : Vector[Int] = {\n",
    "  val data = for (i <- 0 until cfTexts.size) yield {\n",
    "    editDistance(baseLine, cfTexts(i))\n",
    "  }\n",
    "  data.toVector\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// get text content of parallel URNs\n",
    "def parallelTexts(urn: CtsUrn, corpora: Vector[Corpus]): Vector[String] = {\n",
    "  corpora.map(c => {\n",
    "    val matches = c ~~ urn\n",
    "    matches.nodes.head.text })\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataMatrix = for (documentsIndex <- 0 until alignedTexts.size) yield {\n",
    "  println(\"Document \" + documentsIndex + s\" (of ${alignedTexts.size})\")\n",
    "  \n",
    "  val baseText = alignedTexts(documentsIndex)\n",
    "  val colName = baseText.nodes.head.urn.version\n",
    "  println(colName)\n",
    "  val datacorpus = for (lineIndex <- 0 until baseText.size) yield {\n",
    "    val baseTextPassage = baseText.nodes(lineIndex)\n",
    "    val rowLabel = s\"${colName}.\" + lineIndex\n",
    "    println(rowLabel)\n",
    "    val cfLines = parallelTexts(baseTextPassage.urn.dropVersion, alignedTexts)\n",
    "\n",
    "    println(\"Computing edit distance against \" + rowLabel + s\" (psg ${lineIndex} in document ${documentsIndex})\")\n",
    "    val data = rowData(baseTextPassage.text, cfLines)\n",
    "    rowLabel + \",\" + data.mkString(\",\") \n",
    "  }\n",
    "  println(\"Done.\")\n",
    "  datacorpus\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dm = dataMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val sigla = alignedTexts.map(c => c.nodes.head.urn.version)\n",
    "val colLabels = \"base,\" + sigla.mkString(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the final .csv output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(colLabels + \"\\n\" + dm.flatten.mkString(\"\\n\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
